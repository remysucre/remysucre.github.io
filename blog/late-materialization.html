<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>late-materialization</title>
  <style>
    html {
      font-family: Verdana;
      line-height: 1.6;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 650px;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="late-materialization-is-almost-worst-case-optimal">Late
materialization is (almost) worst-case optimal</h1>
<p>In our SIGMOD’23 <a href="https://arxiv.org/abs/2301.10841">paper</a>
we proposed a new join algorithm called <em>free join</em> that
generalizes and unifies both traditional binary joins and worst-case
optimal joins (WCOJ). This bridge can be very useful in practice,
because it brings WCOJ closer to traditional algorithms, making it
easier to adopt in existing systems. Indeed, WCOJ has not seen wide
adoption mainly because it seems so different from what’s already
implemented in databases. The surprise in this post is that your
database is probably already almost worst-case optimal, and only some
small changes are needed to get the last mile. In particular, if your
system implements late materialization, then you’re in good shape. You
just need the following to get worst-case optimality:</p>
<ol type="1">
<li>Make the late materialization a little more aggressive</li>
<li>Change the query plan a bit</li>
<li>Add a very simple adaptive processing primitive</li>
</ol>
<h2 id="a-simple-fact-about-agm">A simple fact about AGM</h2>
<p>This whole WCOJ line of work goes back to the AGM bound, and I’ve
written about it <a href="wcoj.md">before</a>. A very simple and useful
property of the AGM bound is <em>decomposability</em> (Lemma 4.1, <a
href="https://arxiv.org/abs/1310.3314">NRR’13</a>), demonstrated with
the triangle query here:</p>
<pre class="math"><code>\sum_{(a, b) \in R} \text{AGM}\left( \texttt{Q(z) = S(a,z), T(z,b)} \right) 
\leq \text{AGM}\left( \texttt{Q(x,y,z) = R(x,y), S(x,z), T(z,y)} \right)</code></pre>
<p>What this means is that instead of the standard Generic Join where we
build a trie for each relation and do intersections, we can skip trie
building for one of the relations and simply iterate over it. That is,
the following is still worst-case optimal:</p>
<pre><code>for a, b in R
  for c in S[a].z ^ T[b].z
    output(a, b, c)</code></pre>
<p>This is the first step bringing us closer to binary join from WCOJ,
because in binary (hash) join we only build hash on one side and iterate
over the other.</p>
<h2 id="late-materialization">Late materialization</h2>
<p>Late materialization is one of the ideas with the most
bang-for-the-buck: it’s very simple yet can lead to dramatic speedup. To
illustrate with an example, consider the query
<code>Q(x, u, v) :- R(x), S(x, u), T(x, v)</code>. This is a simplified
version of the “clover query” in our free join <a
href="https://arxiv.org/abs/2301.10841">paper</a>. Now imagine the
<code>x</code> column contains book titles, i.e. it’s short, but the
<code>u, v</code> columns contain the content of books, i.e. very long.
Naive binary join will first join <code>R</code> and <code>S</code>, and
loop over each result to join with <code>T</code>. That is:</p>
<pre><code># hash S on x, hash T on x

for x in R:
  us = S[x]? # ? means continue to enclosing loop if the lookup fails
  for u in us:
    vs = T[x]?
    for v in vs:
      output(x, u, v)</code></pre>
<p>The second loop is a bit silly, because we are retrieving the
<code>u</code>s even though we don’t need them to probe into
<code>T</code>. And getting each <code>u</code> is expensive, because
they contain the entire content of a book. The idea of late
materialization is to delay actually retrieving each <code>u</code>
until we are ready to output in the innermost loop. For example, we can
simply iterate over an array of pointers to the <code>u</code>s, and
dereference only at the end.</p>
<h2 id="more-aggressively-late">More aggressively late</h2>
<p>To get more performance, we need to be more aggressive in being late.
Instead of delaying dereference during iteration, we delay the entire
iteration until it’s needed. Using our example, we’ll push the second
loop to run after the lookup on <code>T</code>:</p>
<pre><code># hash S on x, hash T on x

for x in R:
  us = S[x]? # ? means continue to enclosing loop if the lookup fails
  vs = T[x]?
  for u in us:
    for v in vs:
      output(x, u, v)</code></pre>
<p>Probing into both <code>S</code> and <code>T</code> first will filter
out some <code>u</code>s and <code>v</code>s so we won’t have to iterate
over those.</p>
<p>Another limitation found in many systems is that they only delay the
materialization of non-join attributes. In general, you might also want
to delay materializing join attributes as well. The triangle query is
one example, where all attributes are joined on. Furthermore, when
building hash people usually hash on <em>all</em> join attributes. To
get worst-case optimality, we’ll want to hash on some of the attributes
first, and delay the rest until later. For more details see the COLT
data structure in our <a
href="https://arxiv.org/abs/2301.10841">paper</a>.</p>
<h2 id="changing-the-plan">Changing the plan</h2>
<p>In the above when we pushed down the second loop, we already broke
away from the original binary plan that computes the join of
<code>R</code> and <code>S</code> first. A simple way to guarantee
worst-case optimality now is to go all the way and use a generic join
plan. A generic join plan is simply a total ordering of all the
attributes. For example, <code>[x, y, z]</code> for the triangle query
and <code>[x, u, v]</code> for our second example query above. During
execution, we’ll join all the relations that have the first variable
first, then go to those with the second variable, and so on. While
joining on a variable, we delay the materialization of all other
variables, and this essentially implements the “intersection” from
generic join.</p>
<p>However, it’s debatable if we <em>should</em> go all the way to a
generic join plan just because we can. If the optimizer picks a
particular binary plan, it’s probably because it thinks the plan is
fast. In the paper we take a more conservative approach and greedily
transform the binary plan towards WCOJ, while avoiding accidental
slowdowns.</p>
<h2 id="adaptive-processing">Adaptive processing</h2>
<p>A subtle detail of WCOJ is that every intersection must take time
linear to the size of the smallest relation; otherwise the algorithm
won’t be worst-case optimal. In hash join, we intersect by iterating
over the keys of one relation, and probing into the others. A simple way
to satisfy the requirement is to simply pick the smallest relation to
iterate over at run time. This will guarantee worst-case optimality, but
there’s an interesting trade-off: iterating over the smallest relation
means we now have to build hash on the larger relations, and this is
expensive. On the other hand, if we iterate over the largest one, we
save time hashing it. In practice, the time saved can be significant,
and may outweigh the warm and fuzzy feeling of worst-case
optimality.</p>
<h2 id="conclusion">Conclusion</h2>
<p>At this point, even if you’re not convinced you can massage your join
implementation into one that is worst-case optimal, I hope your
suspicion is strong enough that you’ll try it. I think the COLT data
structure is really central to all of this, and if you see you can
implement COLT with late materialization, the rest is simple.</p>
</body>
</html>
